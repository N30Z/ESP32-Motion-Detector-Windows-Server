# Face Recognition System - Documentation

**Lightweight Face Recognition mit YuNet + SFace f√ºr ESP32 Motion Detector**

## Inhaltsverzeichnis

1. [Architektur](#architektur)
2. [Setup & Installation](#setup--installation)
3. [Wie es funktioniert](#wie-es-funktioniert)
4. [Matching-Logik & Confidence](#matching-logik--confidence)
5. [Thresholds Tuning](#thresholds-tuning)
6. [Auto-Learning](#auto-learning)
7. [Personenverwaltung](#personenverwaltung)
8. [Datenbank-Design](#datenbank-design)
9. [Troubleshooting](#troubleshooting)
10. [Datenschutz](#datenschutz)

---

## Architektur

### Warum YuNet + SFace?

**Design-Entscheidung:** Minimale Dependencies, keine ML-Frameworks.

| Library | Pro | Contra | Entscheidung |
|---------|-----|--------|--------------|
| `face_recognition` (dlib) | Einfach, bekannt | dlib-Kompilierung schwierig auf Windows, gro√ü | ‚ùå Abgelehnt |
| PyTorch + FaceNet | Beste Accuracy | Riesige Dependencies (>500 MB) | ‚ùå Overkill |
| **YuNet + SFace** | Lightweight, ONNX, nur OpenCV | Etwas weniger genau | ‚úÖ **Gew√§hlt** |

**YuNet:** Face Detector (ONNX, ~200 KB)
**SFace:** Face Embedder (ONNX, ~5 MB)

### Datenfluss

```
ESP32 ‚Üí Upload JPEG
    ‚Üì
Server: app.py
    ‚Üì
YuNet: Detect Faces (bbox + landmarks)
    ‚Üì
SFace: Extract Embeddings (128-dim vector)
    ‚Üì
Matching: Compare with DB embeddings
    ‚Üì
Result: GREEN / YELLOW / UNKNOWN
    ‚Üì
Actions:
 - UNKNOWN ‚Üí Create new Person
 - GREEN ‚Üí Auto-Learning
 - All ‚Üí Windows Toast Notification
```

---

## Setup & Installation

### 1. Dependencies installieren

```bash
cd server
pip install -r requirements.txt
```

**Installiert:**
- `opencv-contrib-python` (YuNet + SFace Support)
- `numpy`, `Pillow`
- `Flask`, `PyYAML`, `winotify`

### 2. Models downloaden

```bash
python models/download_models.py
```

**Downloaded:**
- `face_detection_yunet_2023mar.onnx` (~200 KB)
- `face_recognition_sface_2021dec.onnx` (~5 MB)

**Speicherort:** `server/models/`

### 3. Config aktivieren

Editiere `config.yaml`:

```yaml
face_recognition:
  enabled: true  # ‚Üê Auf true setzen
```

### 4. Server starten

```bash
python app.py
```

**Pr√ºfe Logs:**
```
‚úì YuNet and SFace models loaded successfully
Face Recognition: ENABLED
```

---

## Wie es funktioniert

### 1. Face Detection (YuNet)

```python
faces = detector.detect(image)
# Returns: [x, y, w, h, landmarks..., confidence]
```

**Output:**
- **bbox**: `[x, y, w, h]` (Face location)
- **landmarks**: 5 Punkte (Augen, Nase, Mundwinkel)
- **score**: Detection confidence (0.0-1.0)

### 2. Embedding Extraction (SFace)

```python
aligned_face = recognizer.alignCrop(image, landmarks)
embedding = recognizer.feature(aligned_face)
# Returns: 128-dim L2-normalized vector
```

**Output:** `np.ndarray(128,)` ‚Äì eindeutiger "Fingerabdruck" des Gesichts

### 3. Matching gegen Datenbank

```python
distance = recognizer.match(query_emb, known_emb, dis_type=COSINE)
# Returns: Cosine distance (0.0 = identisch, 1.0 = komplett verschieden)
```

**F√ºr jede bekannte Person:** Vergleiche Query-Embedding mit allen Samples.

**Best Match:** Niedrigste Distanz `d1` zu Person A
**Second Best:** Zweitniedrigste Distanz `d2` zu Person B

**Margin:** `margin = d2 - d1` (wie viel besser ist A als B?)

---

## Matching-Logik & Confidence

### Status-Bestimmung (GREEN / YELLOW / UNKNOWN)

```
GREEN (Zuverl√§ssig):
  d1 < threshold_strict (default: 0.35)
  UND
  margin > margin_strict (default: 0.15)

YELLOW (Unsicher):
  d1 < threshold_loose (default: 0.50)
  UND
  margin > margin_loose (default: 0.08)

UNKNOWN:
  Keine Bedingung erf√ºllt
```

### Confidence-Berechnung (0-100%)

**Nicht-magischer Algorithmus:**

```python
if d1 < threshold_strict:
    base_conf = (threshold_loose - d1) / (threshold_loose - threshold_strict) * 100
else:
    base_conf = max(0, (threshold_loose - d1) / threshold_loose * 50)

# Margin-Bonus (h√∂here Margin = deutlicher Match)
margin_bonus = min(margin / margin_strict * 20, 20)

confidence = min(100, base_conf + margin_bonus)
```

**Interpretation:**
- `95-100%`: Sehr sicher (d1 sehr klein, margin sehr gro√ü)
- `70-95%`: Gut (GREEN Match)
- `50-70%`: Unsicher (YELLOW Match)
- `<50%`: Unzuverl√§ssig (UNKNOWN)

**Wichtig:** Confidence ist **kein** wissenschaftlich kalibrierter Wert, sondern eine **n√ºtzliche UI-Metrik** basierend auf Distanz + Margin.

---

## Thresholds Tuning

### Problem-Diagnose

| Symptom | Ursache | L√∂sung |
|---------|---------|--------|
| **Zu viele YELLOW** | threshold_strict zu niedrig | `threshold_strict` erh√∂hen (z.B. 0.35 ‚Üí 0.40) |
| **Bekannte Person als UNKNOWN** | threshold_loose zu niedrig | `threshold_loose` erh√∂hen (z.B. 0.50 ‚Üí 0.60) |
| **FALSE POSITIVES** (falsche Person erkannt) | threshold_strict zu hoch | `threshold_strict` senken (z.B. 0.35 ‚Üí 0.30) |
| **Margin immer niedrig** | Zu wenig diverse Samples | Mehr Samples unter verschiedenen Bedingungen sammeln |

### Tuning-Prozess

**1. Testphase starten (7 Tage)**

- Lass das System laufen mit Default-Werten
- Sammle Auto-Learning Samples

**2. Events analysieren**

```bash
# In Web-UI: /events
# Schaue Dir Status-Verteilung an:
# - GREEN: X%
# - YELLOW: Y%
# - UNKNOWN: Z%
```

**Ziel:**
- **GREEN**: 80-90% (bei bekannten Personen)
- **YELLOW**: 5-10%
- **UNKNOWN**: 5-10% (neue Personen)

**3. Thresholds anpassen**

Gehe zu `/config` und √§ndere Werte inkrementell:

```yaml
# Beispiel-Tuning f√ºr 3 Personen im Haushalt
threshold_strict: 0.38   # Leicht erh√∂ht (weniger YELLOW)
threshold_loose: 0.55    # Erh√∂ht (weniger UNKNOWN bei Bekannten)
margin_strict: 0.12      # Leicht gesenkt (mehr GREEN)
margin_loose: 0.06       # Leicht gesenkt (mehr YELLOW statt UNKNOWN)
```

**4. Iterieren**

- √Ñndere **maximal 0.05** pro Schritt
- Teste 2-3 Tage
- Pr√ºfe Events
- Wiederhole

### Advanced: Person-spezifische Samples

Wenn **Person A** immer YELLOW ist:

1. Gehe zu `/persons/A`
2. Pr√ºfe Samples:
   - Sind alle √§hnlich? (gleiche Beleuchtung, Winkel)
   - Quality Scores niedrig?
3. **L√∂sung:**
   - L√∂sche schlechte Samples
   - Sammle neue unter diversen Bedingungen:
     - Frontansicht, Seitenansicht
     - Hell, dunkel
     - Mit/ohne Brille

---

## Auto-Learning

### Wie es funktioniert

Bei jedem **GREEN Match**:

1. **Qualit√§ts-Check:**
   - Face Size > `min_face_size` (default: 10.000 px = 100√ó100)
   - Quality Score > `min_quality_score` (default: 0.6)

2. **Cooldown-Check:**
   - Letzte Learning-Session > `cooldown_seconds` (default: 60s)

3. **Limit-Check:**
   - Aktuelle Samples < `max_samples_per_person` (default: 15)
   - Wenn Limit erreicht ‚Üí √Ñltestes Sample l√∂schen

4. **Sample hinzuf√ºgen:**
   - Face-Crop speichern in `faces_db/person_X/`
   - Embedding in DB speichern

### Config

```yaml
auto_learning:
  enabled: true
  max_samples_per_person: 15
  cooldown_seconds: 60
  only_green_matches: true
  replace_strategy: 'oldest'  # oldest | lowest_quality
```

### Best Practices

**DO:**
- ‚úÖ Lass Auto-Learning f√ºr erste 7 Tage laufen
- ‚úÖ Sammle nat√ºrliche Variationen (Beleuchtung, Winkel)
- ‚úÖ Cooldown mindestens 60s (verhindert Duplikate)

**DON'T:**
- ‚ùå `max_samples_per_person` > 20 (unn√∂tig gro√ü)
- ‚ùå `only_green_matches: false` (lernt von unsicheren Matches)
- ‚ùå `cooldown_seconds` < 30 (zu viele √§hnliche Samples)

---

## Personenverwaltung

### Automatische Person-Erstellung

Wenn Face als **UNKNOWN** erkannt wird:

```yaml
auto_create_person: true
```

‚Üí Erstellt automatisch neue Person mit Namen `"Unbekannt #N"`

**Ablauf:**
1. UNKNOWN Match
2. Erstelle Person in DB
3. Speichere erstes Sample
4. Toast Notification: "üÜï Neue Person erkannt!"

### Personen umbenennen

**Web-UI:** `/persons/<id>`

```html
<form method="POST" action="/persons/12/rename">
  <input type="text" name="name" value="Unbekannt #12">
  <button>Speichern</button>
</form>
```

‚Üí Umbenennen in z.B. "Alice"

### Merge (Doppel-Anlage beheben)

**Problem:** Person wurde zweimal als UNKNOWN angelegt.

**L√∂sung:**

1. Gehe zu `/persons`
2. W√§hle:
   - **Von:** "Unbekannt #12" (wird gel√∂scht)
   - **In:** "Alice" (bleibt erhalten)
3. Klicke "Merge durchf√ºhren"

**Effekt:**
- Alle Samples von #12 ‚Üí Alice
- Alle Events von #12 ‚Üí Alice
- #12 wird als `is_merged_into = Alice.id` markiert

**R√ºckg√§ngig machen:**

SQL (nur f√ºr Fortgeschrittene):

```sql
-- Samples zur√ºckschieben
UPDATE face_sample SET person_id = 12 WHERE person_id = 1;

-- Merge zur√ºcksetzen
UPDATE person SET is_merged_into = NULL WHERE id = 12;
```

‚ö†Ô∏è **Vorsicht:** Keine UI-Funktion daf√ºr. Besser: Vorsichtig mergen.

---

## Datenbank-Design

### Tabellen

**`person`**
```sql
id INTEGER PRIMARY KEY
name TEXT                  -- "Alice" oder "Unbekannt #12"
created_at TIMESTAMP
updated_at TIMESTAMP
is_merged_into INTEGER     -- NULL oder Person-ID
```

**`face_sample`**
```sql
id INTEGER PRIMARY KEY
person_id INTEGER          -- FK zu person
embedding BLOB             -- 128-dim float32 vector (512 bytes)
image_path TEXT            -- z.B. "faces_db/person_1/event_42.jpg"
quality_score REAL         -- 0.0-1.0
bbox TEXT                  -- JSON: [x, y, w, h]
created_at TIMESTAMP
```

**`event`**
```sql
id INTEGER PRIMARY KEY
timestamp TIMESTAMP
person_id INTEGER          -- FK zu person (NULL bei UNKNOWN)
confidence REAL            -- 0.0-1.0
distance REAL              -- Cosine distance
margin REAL                -- d2 - d1
status TEXT                -- GREEN, YELLOW, UNKNOWN, NO_FACE
image_path TEXT            -- Original-Bild
device_id TEXT             -- "ESP32-CAM-01"
```

### Speicherstruktur

```
server/
‚îú‚îÄ‚îÄ faces.db                     # SQLite DB
‚îú‚îÄ‚îÄ captured_images/             # Original-Uploads vom ESP32
‚îÇ   ‚îú‚îÄ‚îÄ ESP32-CAM_20240101_120000.jpg
‚îÇ   ‚îî‚îÄ‚îÄ ESP32-CAM_20240101_120500.jpg
‚îî‚îÄ‚îÄ faces_db/                    # Face-Crops pro Person
    ‚îú‚îÄ‚îÄ person_1/
    ‚îÇ   ‚îú‚îÄ‚îÄ event_42_20240101_120000.jpg
    ‚îÇ   ‚îî‚îÄ‚îÄ event_43_20240101_120500.jpg
    ‚îú‚îÄ‚îÄ person_2/
    ‚îî‚îÄ‚îÄ person_3/
```

### Datenvolumen

**Pro Person (15 Samples):**
- Embeddings: 15 √ó 512 bytes = 7.5 KB
- Face-Crops: 15 √ó ~20 KB = 300 KB

**3 Personen:** ~1 MB (DB + Crops)

**1000 Events:** ~50 MB (Original-Bilder)

---

## Troubleshooting

### 1. "YuNet model not found"

**Problem:** Models nicht heruntergeladen.

**L√∂sung:**
```bash
python server/models/download_models.py
```

Pr√ºfe: `server/models/face_detection_yunet_2023mar.onnx` existiert.

### 2. "No faces detected" (obwohl Gesicht sichtbar)

**M√∂gliche Ursachen:**
- Face zu klein (min. ~80√ó80 px empfohlen)
- Starke √úberbelichtung / Unterbelichtung
- Extrem seitlicher Winkel (>45¬∞)

**L√∂sung:**
- ESP32-CAM: Bessere Beleuchtung, Kamera n√§her
- YuNet `score_threshold` senken (in `face_recognition_cv.py:82`):
  ```python
  score_threshold=0.5,  # Default: 0.6
  ```

### 3. Alle Matches sind UNKNOWN

**M√∂gliche Ursachen:**
- Keine Samples in DB
- Thresholds zu streng

**Debug:**
```python
# In app.py nach Matching:
logger.info(f"Best distance: {d1}, margin: {margin}")
```

**Typische Werte:**
- **Same Person:** d1 = 0.15-0.35
- **Different Person:** d1 = 0.60-0.90

Wenn d1 bei bekannter Person > 0.50 ‚Üí Samples schlecht oder Person ver√§ndert (Bart, Brille).

### 4. Face Recognition sehr langsam (>2s pro Bild)

**Ursache:** CPU-basierte Inference.

**Optimierung:**
- Reduziere Anzahl Samples pro Person (weniger Vergleiche)
- Downscale Bild vor Detection:
  ```python
  img = cv2.resize(img, (640, 480))  # Statt 1280x720
  ```

**Typische Performance:**
- Detection: 50-100 ms
- Embedding: 30-50 ms
- Matching (15 Samples): 5-10 ms

**Total:** ~100-200 ms pro Face auf modernem PC

### 5. Auto-Learning erstellt zu viele √§hnliche Samples

**L√∂sung:**
```yaml
auto_learning:
  cooldown_seconds: 120  # Statt 60 ‚Üí weniger h√§ufig
```

Oder manuell alte Samples l√∂schen (Web-UI in Zukunft).

---

## Datenschutz

### DSGVO-Konformit√§t (Deutschland)

**Rechtsgrundlage:** Hausrecht (Art. 6 Abs. 1 lit. f DSGVO) f√ºr Hausflur.

**Pflichten:**

1. **Hinweisschild anbringen:**
   ```
   ‚ö†Ô∏è Video√ºberwachung mit Gesichtserkennung
   Verantwortlich: [Name, Adresse]
   Zweck: Zugangskontrolle
   Kontakt: [E-Mail]
   ```

2. **Nur Hausflur √ºberwachen** (nicht √∂ffentlichen Gehweg)

3. **Zugriff beschr√§nken:**
   - Server nur im LAN (nicht Internet-exponiert)
   - Starkes Auth-Token
   - Regelm√§√üige Updates

4. **Speicherfrist beachten:**
   ```yaml
   storage:
     max_age_days: 7  # Bilder nach 7 Tagen l√∂schen
   ```

5. **Auskunftsrecht gew√§hren:**
   - Bewohner k√∂nnen anfragen: "Welche Daten habt ihr √ºber mich?"
   - Export aus DB: `SELECT * FROM face_sample WHERE person_id = X`

### Empfehlungen

- ‚úÖ **Nur Haushaltsmitglieder** als Personen anlegen
- ‚úÖ **G√§ste informieren** vor Betreten
- ‚úÖ **Daten nicht weitergeben** (kein Cloud-Upload)
- ‚ùå **Keine Kinder** ohne Eltern-Zustimmung

### Auto-Delete (Optional)

F√ºge Cron-Job hinzu (Windows Task Scheduler):

```python
# cleanup.py
import sqlite3
from pathlib import Path
from datetime import datetime, timedelta

db = sqlite3.connect('faces.db')
cursor = db.cursor()

# Events √§lter als 7 Tage
cutoff = datetime.now() - timedelta(days=7)
cursor.execute("SELECT image_path FROM event WHERE timestamp < ?", (cutoff,))
for row in cursor.fetchall():
    Path(row[0]).unlink(missing_ok=True)

cursor.execute("DELETE FROM event WHERE timestamp < ?", (cutoff,))
db.commit()
```

---

## Zusammenfassung

‚úÖ **Minimal:** YuNet + SFace, nur OpenCV, keine ML-Frameworks
‚úÖ **Pr√§zise:** Distance + Margin Matching mit GREEN/YELLOW/UNKNOWN
‚úÖ **Wartbar:** SQLite, YAML-Config, Web-UI f√ºr Tuning
‚úÖ **Auto-Learning:** Max 15 Samples, Cooldown, Quality-Filter
‚úÖ **Datenschutz:** Lokal, kein Cloud, L√∂schfristen

**N√§chste Schritte:**
1. Models downloaden (`python models/download_models.py`)
2. `face_recognition.enabled: true` setzen
3. Server starten, erste Personen erfassen
4. Nach 7 Tagen Thresholds tunen (`/config`)
5. Doppel-Personen mergen (`/persons`)

**Support:** Siehe `server/README.md` und Hauptprojekt-README.
